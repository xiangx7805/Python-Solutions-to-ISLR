{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Q-5.8\" data-toc-modified-id=\"Q-5.8-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Q 5.8</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)\" data-toc-modified-id=\"(a)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>(a)</a></span></li><li><span><a href=\"#(b)\" data-toc-modified-id=\"(b)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>(b)</a></span></li><li><span><a href=\"#(c)\" data-toc-modified-id=\"(c)-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>(c)</a></span></li><li><span><a href=\"#(d)\" data-toc-modified-id=\"(d)-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>(d)</a></span></li><li><span><a href=\"#(e)\" data-toc-modified-id=\"(e)-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>(e)</a></span></li><li><span><a href=\"#(f)\" data-toc-modified-id=\"(f)-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>(f)</a></span></li></ul></li><li><span><a href=\"#Q-6.2\" data-toc-modified-id=\"Q-6.2-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Q 6.2</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)\" data-toc-modified-id=\"(a)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>(a)</a></span></li><li><span><a href=\"#(b)-for-ridge-regression-relative-to-least-squares.\" data-toc-modified-id=\"(b)-for-ridge-regression-relative-to-least-squares.-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>(b) for ridge regression relative to least squares.</a></span></li><li><span><a href=\"#(c)-for-non-linear-methods-relative-to-least-squares.\" data-toc-modified-id=\"(c)-for-non-linear-methods-relative-to-least-squares.-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>(c) for non-linear methods relative to least squares.</a></span></li></ul></li><li><span><a href=\"#Q-6.10\" data-toc-modified-id=\"Q-6.10-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Q 6.10</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)\" data-toc-modified-id=\"(a)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>(a)</a></span></li><li><span><a href=\"#(b)\" data-toc-modified-id=\"(b)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>(b)</a></span></li><li><span><a href=\"#(c)\" data-toc-modified-id=\"(c)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>(c)</a></span></li><li><span><a href=\"#(d)\" data-toc-modified-id=\"(d)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>(d)</a></span></li><li><span><a href=\"#(e)\" data-toc-modified-id=\"(e)-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>(e)</a></span></li><li><span><a href=\"#(f)\" data-toc-modified-id=\"(f)-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>(f)</a></span></li><li><span><a href=\"#(g)\" data-toc-modified-id=\"(g)-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>(g)</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book questions 5.8, 6.2, 6.10.\n",
    "# Q 5.8\n",
    "Perform cross-validation on a simulated data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm  # To fit models using least squares\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Generate a simulated data set and set seed as one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "x= np.random.normal(size= 100)\n",
    "y= np.random.normal(size= 100)\n",
    "epsilon= np.random.normal(size= 100)\n",
    "y = x - 2*(x**2) +epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set we have n =100 and p =2 , (x, $x^2$), the model will be $$y = x - 2x^2 + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18f70330>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Quadratic plot\n",
    "*  Convex function with negative concavity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.331587</td>\n",
       "      <td>-2.081521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715279</td>\n",
       "      <td>0.894775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.545400</td>\n",
       "      <td>-7.346677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.008384</td>\n",
       "      <td>0.151875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.621336</td>\n",
       "      <td>-1.281256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  1.331587 -2.081521\n",
       "1  0.715279  0.894775\n",
       "2 -1.545400 -7.346677\n",
       "3 -0.008384  0.151875\n",
       "4  0.621336 -1.281256"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "# create LOOCV obejct\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "# create dataframe of x and y\n",
    "df = pd.DataFrame({'x':x, 'y' :y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with degree 1 has MSE 9.693\n",
      "Model with degree 2 has MSE 5.288\n",
      "Model with degree 3 has MSE 3.826\n",
      "Model with degree 4 has MSE 3.101\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(1,5): # degree 1,2,3,4\n",
    "    for train,test in loocv.split(df):\n",
    "        x_train = df['x'][train]\n",
    "        x_test = df['x'][test]\n",
    "        y_train = df['y'][train]\n",
    "        y_test = df['y'][test]\n",
    "        \n",
    "        # pipeline\n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree=i)),\n",
    "                        ('linear', LinearRegression())])\n",
    "        model.fit(x_train[:, np.newaxis],y_train)\n",
    "        \n",
    "        # MSE\n",
    "        score = mean_squared_error(y_test, model.predict(x_test[:, np.newaxis]))\n",
    "        scores.append(score)\n",
    "    print('Model with degree {} has MSE {}'.format(i, round(np.mean(scores),3)))\n",
    "    score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) \n",
    "use anotheer random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with degree 1 has MSE 9.693\n",
      "Model with degree 2 has MSE 5.288\n",
      "Model with degree 3 has MSE 3.826\n",
      "Model with degree 4 has MSE 3.101\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2019)\n",
    "\n",
    "# create LOOCV obejct\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "# create dataframe of x and y\n",
    "df = pd.DataFrame({'x':x, 'y' :y})\n",
    "scores = []\n",
    "\n",
    "for i in range(1,5): # degree 1,2,3,4\n",
    "    for train,test in loocv.split(df):\n",
    "        x_train = df['x'][train]\n",
    "        x_test = df['x'][test]\n",
    "        y_train = df['y'][train]\n",
    "        y_test = df['y'][test]\n",
    "        \n",
    "        # pipeline\n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree=i)),\n",
    "                        ('linear', LinearRegression())])\n",
    "        model.fit(x_train[:, np.newaxis],y_train)\n",
    "        \n",
    "        # MSE\n",
    "        score = mean_squared_error(y_test, model.predict(x_test[:, np.newaxis]))\n",
    "        scores.append(score)\n",
    "    print('Model with degree {} has MSE {}'.format(i, round(np.mean(scores),3)))\n",
    "    score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are exactly **the same** because we only remove one observation from the training set. Thus, there is no random effect resulting from the observations used for the test set. LOOCV will always be the same, no matter the random seed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)\n",
    "The model that had the smallest LOOCV error was model 4. This was an expected result because model (4) consider more predictors and has smaller MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.029\n",
      "Method:                 Least Squares   F-statistic:                     3.954\n",
      "Date:                Fri, 15 Feb 2019   Prob (F-statistic):             0.0495\n",
      "Time:                        21:29:51   Log-Likelihood:                -250.64\n",
      "No. Observations:                 100   AIC:                             505.3\n",
      "Df Residuals:                      98   BIC:                             510.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.8764      0.301     -6.240      0.000      -2.473      -1.280\n",
      "x1             0.6163      0.310      1.989      0.050       0.001       1.231\n",
      "==============================================================================\n",
      "Omnibus:                       42.082   Durbin-Watson:                   2.098\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               82.682\n",
      "Skew:                          -1.747   Prob(JB):                     1.11e-18\n",
      "Kurtosis:                       5.763   Cond. No.                         1.09\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.910\n",
      "Model:                            OLS   Adj. R-squared:                  0.908\n",
      "Method:                 Least Squares   F-statistic:                     491.1\n",
      "Date:                Fri, 15 Feb 2019   Prob (F-statistic):           1.79e-51\n",
      "Time:                        21:29:51   Log-Likelihood:                -132.15\n",
      "No. Observations:                 100   AIC:                             270.3\n",
      "Df Residuals:                      97   BIC:                             278.1\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0464      0.112      0.415      0.679      -0.175       0.268\n",
      "x1             0.9728      0.096     10.137      0.000       0.782       1.163\n",
      "x2            -2.0724      0.068    -30.666      0.000      -2.206      -1.938\n",
      "==============================================================================\n",
      "Omnibus:                        0.937   Durbin-Watson:                   2.051\n",
      "Prob(Omnibus):                  0.626   Jarque-Bera (JB):                1.046\n",
      "Skew:                          -0.192   Prob(JB):                        0.593\n",
      "Kurtosis:                       2.679   Cond. No.                         2.33\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.911\n",
      "Model:                            OLS   Adj. R-squared:                  0.908\n",
      "Method:                 Least Squares   F-statistic:                     326.3\n",
      "Date:                Fri, 15 Feb 2019   Prob (F-statistic):           3.33e-50\n",
      "Time:                        21:29:51   Log-Likelihood:                -131.84\n",
      "No. Observations:                 100   AIC:                             271.7\n",
      "Df Residuals:                      96   BIC:                             282.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0313      0.114      0.275      0.784      -0.194       0.257\n",
      "x1             1.0923      0.182      6.001      0.000       0.731       1.454\n",
      "x2            -2.0560      0.071    -28.976      0.000      -2.197      -1.915\n",
      "x3            -0.0416      0.054     -0.774      0.441      -0.148       0.065\n",
      "==============================================================================\n",
      "Omnibus:                        0.747   Durbin-Watson:                   2.078\n",
      "Prob(Omnibus):                  0.688   Jarque-Bera (JB):                0.843\n",
      "Skew:                          -0.191   Prob(JB):                        0.656\n",
      "Kurtosis:                       2.763   Cond. No.                         7.22\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.911\n",
      "Model:                            OLS   Adj. R-squared:                  0.907\n",
      "Method:                 Least Squares   F-statistic:                     242.3\n",
      "Date:                Fri, 15 Feb 2019   Prob (F-statistic):           6.43e-49\n",
      "Time:                        21:29:51   Log-Likelihood:                -131.82\n",
      "No. Observations:                 100   AIC:                             273.6\n",
      "Df Residuals:                      95   BIC:                             286.7\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0182      0.132      0.138      0.891      -0.244       0.281\n",
      "x1             1.0763      0.201      5.367      0.000       0.678       1.474\n",
      "x2            -2.0141      0.226     -8.912      0.000      -2.463      -1.565\n",
      "x3            -0.0343      0.066     -0.524      0.602      -0.164       0.096\n",
      "x4            -0.0097      0.050     -0.195      0.846      -0.108       0.089\n",
      "==============================================================================\n",
      "Omnibus:                        0.734   Durbin-Watson:                   2.075\n",
      "Prob(Omnibus):                  0.693   Jarque-Bera (JB):                0.830\n",
      "Skew:                          -0.189   Prob(JB):                        0.660\n",
      "Kurtosis:                       2.764   Cond. No.                         22.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    pol = PolynomialFeatures(degree = i)\n",
    "    X_pol = pol.fit_transform(df['x'][:,np.newaxis])\n",
    "    y = df['y']\n",
    "\n",
    "    model = sm.OLS(y, X_pol)\n",
    "    results = model.fit()\n",
    "\n",
    "    print(results.summary())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when we have a second order polynomial, both $x_1$ and $x_2$ have high t-statistic values. When we have a third order polynomial, $x_2$ has the highest t-statistic, followed by $x_1$ and then by $x_3$. Finally, when we have a fourth order polynomial, $x_2$ is the variable with the highest t-statistic, followed by $x_1$, $x_3$ and $x_4$.\n",
    "\n",
    "We can conclude that $x_2$ and $x_1$ are variables with relevance for the presented models. These results agree with the conclusions drawn based on the cross-validation results, showing that the first and second order terms are the most significant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 6.2\n",
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](621.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer : False. Lasso reduces the number of variables, thus is less flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](622.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer : False. Lasso reduces the number of variables, thus is less flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](623.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer : True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](624.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer : False. In general, lasso reduces variance and increases bias. Reduction in variance should compensate increasement in bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) for ridge regression relative to least squares.\n",
    "Same answer as (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) for non-linear methods relative to least squares.\n",
    "*  (i) False. In general, non-linear methods reduce bias and increase variance. Reduction in bias should be compensate increasement in variance.  \n",
    "*  (ii) True.  \n",
    "*  (iii) False. Non-linear methods are more flexible because they accomodate to the data. Unlike least squares, non-linear methods don't assume a parametrized relationship between the predictors and the response.  \n",
    "*  (iv) False. Same justification as in (iii)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 6.10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import scale, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "X = np.random.randn(1000,15)\n",
    "beta = np.random.choice(np.arange(-3,3),15,replace=True)\n",
    "epsilon = np.random.randn(1000)*2\n",
    "y = np.dot(X,beta) + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subset(features):\n",
    "    regr = LinearRegression(fit_intercept=False)\n",
    "    regr.fit(X_train[list(features)], y_train)\n",
    "    MSE_train = mean_squared_error(regr.predict(X_train[list(features)]),\n",
    "                             y_train)\n",
    "    MSE_test = mean_squared_error(regr.predict(X_test[list(features)]),\n",
    "                                y_test)\n",
    "    \n",
    "    return {\"model\": regr, \"MSE_train\": MSE_train, \"MSE_test\": MSE_test,\n",
    "           \"features\": features}\n",
    "\n",
    "\n",
    "def get_best(k):\n",
    "    results = []\n",
    "    for combo in itertools.combinations(X_train.columns, k):\n",
    "        results.append(process_subset(combo))\n",
    "        \n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    best_model = models.loc[models['MSE_train'].idxmin()]\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "models = pd.DataFrame(columns=[\"MSE_train\", \"MSE_test\", \"model\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 16):\n",
    "    models.loc[i] = get_best(i)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(models['MSE_train'])\n",
    "plt.plot(models['MSE_train'].idxmin(),models['MSE_train'].min(), \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(models['MSE_test'])\n",
    "plt.plot(models['MSE_test'].idxmin(),models['MSE_test'].min(), \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)\n",
    "13 predictors\n",
    "## (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct coefficients 'coefs'. coefficients not used in the model\n",
    "# are set to zero.\n",
    "coefs = np.zeros(15)\n",
    "for i, beta_num in enumerate(models.loc[13, 'features']):\n",
    "    coefs[beta_num] = models.loc[13,'model'].coef_[i]\n",
    "    \n",
    "result = pd.DataFrame({'model':coefs, 'true':beta})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = []\n",
    "for model_num in range(1,16):\n",
    "    coefs = np.zeros(15)\n",
    "    for i, beta_num in enumerate(models.loc[model_num, 'features']):\n",
    "        coefs[beta_num] = models.loc[model_num,'model'].coef_[i]\n",
    "        \n",
    "    norm = np.sqrt(((coefs - beta)**2).sum())\n",
    "    norms.append(norm)\n",
    "\n",
    "norms = pd.DataFrame({'norm':norms}, index=np.arange(1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(norms['norm'])\n",
    "plt.plot(norms['norm'].idxmin(), norms['norm'].min(), \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the same result comparing to the test MSE plot from (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "CONTENT",
   "toc_cell": true,
   "toc_position": {
    "height": "100px",
    "left": "473px",
    "top": "141px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
